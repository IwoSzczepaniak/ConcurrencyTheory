{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iwo Szczepaniak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDEA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE ZOSTAŁO ZREALIZOWANE W PYTHONIE 3.9.12\n",
    "\n",
    "Use lab2 code\n",
    "\n",
    "Wszystkie grafy reprezentowane są jako listy sąsiedztwa\n",
    "<br><br>\n",
    "\n",
    "\n",
    "Testy przeprowadzone zostały na trzech przykładach z zajęć:\n",
    "\n",
    "\n",
    "word = 'BAADCB'\n",
    "transactions = ['x<-x+y', 'y<-y+2z','x<-3x+z','z<-y-z']\n",
    "\n",
    "word2 = 'ACDCFBBE' \n",
    "transactions2 = ['x<-y+z', 'y<-x+w+y','x<-x+y+v','w<-v+z', 'v<-x+v+w', 'z<-y+z+v']\n",
    "\n",
    "word3 = 'ACDCFBBE' \n",
    "transactions3 = ['x<-x+1', 'y<-y+2z','x<-3x+z','w<-w+v', 'z<-y-z', 'v<-x+v']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTACJA ZADANIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import potrzebnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funckje pomocnicze, umożliwiające wydzielenie zmiennych spośród wejściowego stringa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_operators_and_numbers(input_string):\n",
    "    result_string = re.sub(r'[0-9+\\-*/\\s]', '.', input_string)\n",
    "    result_string = result_string.split('.')\n",
    "    return [item for item in result_string if item != '']\n",
    "\n",
    "def create_list_trans(t):\n",
    "    list_trans = []\n",
    "    for trans in t:\n",
    "        if len(trans.split('<-')) == 2:\n",
    "            el1 = trans.split('<-')[0].strip()\n",
    "            el2 =  trans.split('<-')[1].strip()\n",
    "            list_trans.append((el1, remove_operators_and_numbers(el2)))\n",
    "    return list_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja przyporządkująca kolejne litery alfabetu poszczególnym akcjom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_alph(t):\n",
    "    alphabet = \"\"\n",
    "    uppercase_letters = string.ascii_uppercase\n",
    "    for i, trans in enumerate(t):\n",
    "        trans.split('<-')\n",
    "        if len(trans) > 1:\n",
    "            alphabet += uppercase_letters[i]\n",
    "    return alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obliczanie relacji zależności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_D(alph, list_t):\n",
    "    D = [[] for _ in range(len(alph))]\n",
    "    for i, let in enumerate(alph):\n",
    "        args = list_t[i][1]\n",
    "        for arg in args:\n",
    "            for j, l in enumerate(alph):\n",
    "                if arg in list_t[j][0]: \n",
    "                    if alph[j] not in D[i]: D[i].append(alph[j])\n",
    "                    if alph[i] not in D[j]: D[j].append(alph[i])\n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obliczanie relacji niezależności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_I(alph, D):\n",
    "    I = [list(alph) for i in range(len(alph))]\n",
    "\n",
    "    for i in range(len(I)):\n",
    "         I[i] = [x for x in I[i] if x not in D[i]]\n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomocniczy bfs, umożliwiający stwierdzenie czy da się przejść od krawędzi start do end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(graph, start, end):\n",
    "    visited = [False] * len(graph)\n",
    "    queue = []\n",
    "    queue.append(start)\n",
    "    visited[start] = True\n",
    "    while queue:\n",
    "        node = queue.pop(0)\n",
    "        if node == end:\n",
    "            return True\n",
    "        for neighbor in graph[node]:\n",
    "            if not visited[neighbor]:\n",
    "                queue.append(neighbor)\n",
    "                visited[neighbor] = True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funckja tworząca graf wszystkich możliwych krawędzi na podstawie D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alphabet_dict(alphabet):\n",
    "    return {letter: i for i, letter in enumerate(alphabet)}\n",
    "\n",
    "def create_graph(word, alphabet, D):\n",
    "    graph = [[] for _ in range(len(word))]\n",
    "    graph_letters = [[] for _ in range(len(word))]\n",
    "    \n",
    "    dict_alphabet = create_alphabet_dict(alphabet)\n",
    "\n",
    "    for i, letter in enumerate(word):\n",
    "        if letter not in alphabet:\n",
    "            raise Exception(f\"Letter *{letter}* not in alphabet\")\n",
    "        for j in range(i+1, len(word)):\n",
    "            if word[j] in D[dict_alphabet[letter]]:\n",
    "                graph_letters[i].append(word[j])\n",
    "                graph[i].append(j)\n",
    "                \n",
    "    return graph, graph_letters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja tworząca tablicę vals, w której są najwyższe możliwe kroki bfs'a - tzn. bfs wchodzi wiele razy w ten sam wierzchołek i zapisuje wartość najwyższą. Funkcja calculate_foata_norm wykorzystuje wartości z tablicy vals i tworzy \"klasy\" na podstawie jej wartości. Zwraca ona normę Foata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vals(graph, start_point, vals):\n",
    "    round_nr = 0\n",
    "    queue = [(start_point, round_nr)]\n",
    "\n",
    "    while queue:\n",
    "        current_node, round_nr = queue.pop(0)\n",
    "        vals[current_node] = max(vals[current_node],round_nr)\n",
    "        for el in graph[current_node]:\n",
    "            queue.append((el, round_nr + 1))\n",
    "\n",
    "    return vals\n",
    "\n",
    "def calculate_foata_norm(word, vals):\n",
    "    curr_val = 0\n",
    "    max_val = max(vals)\n",
    "    res_tab = [[] for _ in range((max_val + 1))]\n",
    "    res_tab_letters = [[] for _ in range((max_val + 1))]\n",
    "\n",
    "    while curr_val <= max_val:\n",
    "        for i, el in enumerate(vals):\n",
    "            if curr_val == vals[i]:\n",
    "                res_tab[curr_val].append(i)\n",
    "                res_tab_letters[curr_val].append(word[i])\n",
    "        curr_val += 1\n",
    "\n",
    "    res_tab_letters = [sorted(el) for el in res_tab_letters]\n",
    "    res_tab = [sorted(el) for el in res_tab]\n",
    "\n",
    "\n",
    "    return res_tab, res_tab_letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja find_diff_edges znajduje kandydatów na usunięcie - gdy \"następnik\" ma mniejszą wartośc vals niż wcześniejsza krawędź. Ci potencjalni kandydaci są wycinani i następnie sprawdzane jest w funckcji eliminate_edges za pomocą bfs czy to nie spowoduje usunięcia ścieżki między kreawędziami, jeśli nie krawędzie pozostają skasowane, jeśli przeciwnie, zostają z powrotem dodane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff_edges(graph, vals):\n",
    "    diff_edges = []\n",
    "\n",
    "    for i in range(len(graph)):\n",
    "        for j in graph[i]:\n",
    "            if abs(vals[i] - vals[j]) != 1:\n",
    "                diff_edges.append((i, j))\n",
    "\n",
    "    return diff_edges\n",
    "\n",
    "def eliminate_edges(graph, diff_edges):\n",
    "    for edge in diff_edges:\n",
    "        i, j = edge\n",
    "        graph[i].remove(j)\n",
    "        if not bfs(graph, i, j):\n",
    "            graph[i].append(j)\n",
    "\n",
    "def convert_graph_to_letters(graph, word):\n",
    "    graph_letters = [[] for _ in range(len(word))]\n",
    "    for i, ver in enumerate(graph):\n",
    "        for el in ver:\n",
    "            graph_letters[i].append(word[el])\n",
    "\n",
    "    return graph_letters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbiorcza funkcja tworząca zarówno graf zależności minimalnej oraz obliczająca postać normalną Foata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_foata_and_graph(word, alphabet, D, helping_prints=False):\n",
    "    if helping_prints:\n",
    "        print()\n",
    "\n",
    "    graph, graph_letters = create_graph(word, alphabet, D)\n",
    "    if helping_prints:\n",
    "        print(f\"Graph indexes:\\n\\t{graph}\")\n",
    "        print(f\"Graph letters:\\n\\t{graph_letters}\")\n",
    "\n",
    "    vals = [0 for _ in range(len(graph))]\n",
    "    for start_point in range(len(graph)):\n",
    "        vals = calculate_vals(graph, start_point, vals)\n",
    "    if helping_prints:\n",
    "        print(f\"Values after bfs-like algorithm:\\n\\t{vals}\")\n",
    "\n",
    "    res_tab, res_tab_letters = calculate_foata_norm(word, vals)\n",
    "\n",
    "    diff_edges = find_diff_edges(graph, vals)\n",
    "    if helping_prints:\n",
    "        print(f\"Edges potentially to delete:\\n\\t{diff_edges}\")\n",
    "    \n",
    "    vis_graph(graph, word)\n",
    "\n",
    "    eliminate_edges(graph, diff_edges)\n",
    "    if helping_prints:\n",
    "        print(f\"Graph after elimination of long-distance edges:\\n\\t{graph}\\n\")\n",
    "\n",
    "    graph_letters = convert_graph_to_letters(graph, word)\n",
    "    graph = [sorted(el) for el in graph]\n",
    "    graph_letters = [sorted(el) for el in graph_letters]\n",
    "    \n",
    "    return res_tab, res_tab_letters, graph, graph_letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja wizualizująca graf za pomocą biblioteki graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_graph(graph, word, g_type = \"not_foata\"):\n",
    "    dot = graphviz.Digraph()\n",
    "\n",
    "    for i, vert in enumerate(graph):\n",
    "        dot.node(str(i), label=word[i])\n",
    "\n",
    "        for neigh in vert:\n",
    "            dot.edge(str(i), str(neigh))\n",
    "\n",
    "    dot.format = 'png'\n",
    "    dot.render(filename=f\"task_{g_type}_graph\", view=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja testująca konkretny przykład"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_example(word, transactions, show_prints):\n",
    "\n",
    "    list_transaction = create_list_trans(transactions)\n",
    "    if show_prints: print(f\"Transactions dependencies:\\n\\t{list_transaction}\")\n",
    "\n",
    "    alphabet = find_alph(transactions)\n",
    "    if show_prints: print(f\"Alphabet is:\\n\\t{alphabet}\")    \n",
    "    D = find_D(alphabet, list_transaction)\n",
    "    if show_prints: print(f\"D is:\\n\\t{D}\")\n",
    "    I = find_I(alphabet, D)\n",
    "    if show_prints: print(f\"I is:\\n\\t{I}\")\n",
    "\n",
    "    foata_norm, foata_norm_letters, dep_graph, dep_graph_letters = calc_foata_and_graph(word, alphabet, D)\n",
    "\n",
    "\n",
    "    if show_prints: \n",
    "        print()\n",
    "        print(f\"Foata norm is:\\n\\t{foata_norm}\")\n",
    "        print(f\"Foata norm is(letters):\\n\\t{foata_norm_letters}\")\n",
    "        print(f\"Dependencies graph is:\\n\\t{dep_graph}\")\n",
    "        print(f\"Dependencies graph(letters) is:\\n\\t{dep_graph_letters}\")\n",
    "\n",
    "    vis_graph(dep_graph, word, \"foata\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wizualizacje są renderowane i zapisywane podczas testu w plikach .png oraz .txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 <br>\n",
    "2.0 1.0 3.0 <br>\n",
    "4.0 3.0 8.0 <br>\n",
    "6.0 5.0 16.0<br>\n",
    "6.0 15.0 27.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n is: 3\n",
      "Matrix is:\n",
      "[['2.0', '1.0', '3.0', '6.0'], ['4.0', '3.0', '8.0', '15.0'], ['6.0', '5.0', '16.0', '27.0']]\n",
      "Alphabet is:\n",
      " ['A_0_0_1', 'B_0_0_1', 'C_0_0_1', 'B_0_1_1', 'C_0_1_1', 'B_0_2_1', 'C_0_2_1', 'B_0_3_1', 'C_0_3_1', 'A_0_0_2', 'B_0_0_2', 'C_0_0_2', 'B_0_1_2', 'C_0_1_2', 'B_0_2_2', 'C_0_2_2', 'B_0_3_2', 'C_0_3_2', 'A_1_1_2', 'B_1_1_2', 'C_1_1_2', 'B_1_2_2', 'C_1_2_2', 'B_1_3_2', 'C_1_3_2']\n",
      "Transactions_dependencies are: \n",
      "['A_0_0_1', 'B_0_0_1', 'C_0_0_1', 'B_0_1_1', 'C_0_1_1', 'B_0_2_1', 'C_0_2_1', 'B_0_3_1', 'C_0_3_1']\n",
      "['A_0_0_2', 'B_0_0_2', 'C_0_0_2', 'B_0_1_2', 'C_0_1_2', 'B_0_2_2', 'C_0_2_2', 'B_0_3_2', 'C_0_3_2']\n",
      "['A_1_1_2', 'B_1_1_2', 'C_1_1_2', 'B_1_2_2', 'C_1_2_2', 'B_1_3_2', 'C_1_3_2']\n",
      "A_0_0_1\n",
      "A_0_0_2\n",
      "A_1_1_2\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def input(file):\n",
    "    with open(file, 'r') as f:\n",
    "        n = f.readline().strip()\n",
    "        transactions = []\n",
    "        for line in f:\n",
    "            transactions.append(line.split())\n",
    "    matrix_core = transactions[:-1]\n",
    "    new_col = transactions[-1]\n",
    "    # add new column to matrix\n",
    "    for i in range(len(matrix_core)):\n",
    "        matrix_core[i].append(new_col[i])\n",
    "    return int(n), len(matrix_core[0]), matrix_core\n",
    "\n",
    "input_file = \"input.txt\"\n",
    "n, m, matrix = input(input_file)\n",
    "\n",
    "print(f\"n is: {n}\")\n",
    "print(f\"Matrix is:\\n{matrix}\")\n",
    "\n",
    "indexing_1 = False\n",
    "start = 0\n",
    "if indexing_1:\n",
    "    n+=1\n",
    "    m+=1\n",
    "    start = 1\n",
    "\n",
    "trans_dependencies = []\n",
    "for i in range(start, n):\n",
    "    for k in range(i+1, n):\n",
    "        trans_dependencies.append([])\n",
    "\n",
    "alph = []\n",
    "for i in range(start, n):\n",
    "    for k in range(i+1, n):\n",
    "        alph.append(f\"A_{i}_{i}_{k}\")\n",
    "        trans_dependencies[i+k-1].append(f\"A_{i}_{i}_{k}\")\n",
    "        for j in range(i, m):\n",
    "            alph.append(f\"B_{i}_{j}_{k}\")\n",
    "            alph.append(f\"C_{i}_{j}_{k}\")\n",
    "            trans_dependencies[i+k-1].append(f\"B_{i}_{j}_{k}\")\n",
    "            trans_dependencies[i+k-1].append(f\"C_{i}_{j}_{k}\")\n",
    "\n",
    "print(\"Alphabet is:\\n\", alph)\n",
    "print(\"Transactions_dependencies are: \")\n",
    "for line in trans_dependencies: \n",
    "    print(line)\n",
    "\n",
    "for line in trans_dependencies: \n",
    "    for el in line:\n",
    "        if el[0] == \"A\":\n",
    "            print(el)\n",
    "\n",
    "transactions = []\n",
    "\n",
    "# word = 'BAADCB'\n",
    "# transactions = ['x<-x+y', 'y<-y+2z','x<-3x+z','z<-y-z']\n",
    "# show_prints = True\n",
    "\n",
    "# test_example(word, transactions, show_prints) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
